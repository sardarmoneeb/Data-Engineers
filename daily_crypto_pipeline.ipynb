{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "048f6d57-f588-4b4b-9c1e-bfa22fb48d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Current working directory: C:\\Users\\LENOVE\\Desktop\\Data Engineers\\Python\\Daily_crypto_pipeline_project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\LENOVE\\Desktop\\Data Engineers\\Python\\Daily_crypto_pipeline_project\")\n",
    "print(\"üìÇ Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e03aa87-c778-4983-9a28-7213fa7bbb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Running Daily Crypto Web Scraping Pipeline...\n",
      "\n",
      "\n",
      "üîÑ Fetching live crypto data from CoinMarketCap...\n",
      "üì¶ Rows fetched: 100\n",
      "‚úÖ Raw data saved to: C:\\Users\\LENOVE\\Desktop\\Data Engineers\\Python\\Daily_crypto_pipeline_project\\raw_data\\raw_data_2025-10-19.csv\n",
      "ü™£ Data Preview:\n",
      "   Unnamed: 0    #         Name        Price   1h %  24h %    7d %  \\\n",
      "0         NaN  1.0   BitcoinBTC  $108,489.34  0.34%  1.31%   3.53%   \n",
      "1         NaN  2.0  EthereumETH    $3,991.77  0.48%  2.95%   0.05%   \n",
      "2         NaN  3.0   TetherUSDT        $1.00  0.01%  0.00%   0.00%   \n",
      "3         NaN  4.0       BNBBNB    $1,121.07  0.69%  2.47%  11.04%   \n",
      "4         NaN  5.0       XRPXRP        $2.41  0.49%  2.23%   1.72%   \n",
      "\n",
      "                 Market Cap              Volume(24h) Circulating Supply  ...  \\\n",
      "0  $2.16T$2,163,044,222,526   $40,386,162,702372.23K         19.93M BTC  ...   \n",
      "1  $470.08B$470,082,882,300     $28,277,473,3857.08M        117.75M ETH  ...   \n",
      "2  $181.93B$181,933,520,862  $100,440,271,364100.40B       181.86B USDT  ...   \n",
      "3  $156.03B$156,032,541,022      $3,574,645,7123.18M        139.18M BNB  ...   \n",
      "4  $144.75B$144,748,833,279      $3,094,213,2881.28B         59.97B XRP  ...   \n",
      "\n",
      "   Unnamed: 94  Unnamed: 95  Unnamed: 96  Unnamed: 97  Unnamed: 98  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 99  Unnamed: 100  Unnamed: 101  Unnamed: 102  Unnamed: 103  \n",
      "0          NaN           NaN           NaN           NaN           NaN  \n",
      "1          NaN           NaN           NaN           NaN           NaN  \n",
      "2          NaN           NaN           NaN           NaN           NaN  \n",
      "3          NaN           NaN           NaN           NaN           NaN  \n",
      "4          NaN           NaN           NaN           NaN           NaN  \n",
      "\n",
      "[5 rows x 104 columns] \n",
      "\n",
      "üßπ Cleaned data saved to: C:\\Users\\LENOVE\\Desktop\\Data Engineers\\Python\\Daily_crypto_pipeline_project\\cleaned_data\\cleaned_data_2025-10-19.csv\n",
      "\n",
      "üéØ Pipeline complete!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVE\\AppData\\Local\\Temp\\ipykernel_18420\\2257231336.py:29: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(response.text)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import date\n",
    "import os\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "base_folder = r\"C:\\Users\\LENOVE\\Desktop\\Data Engineers\\Python\\Daily_crypto_pipeline_project\"\n",
    "\n",
    "raw_folder = os.path.join(base_folder, \"raw_data\")\n",
    "cleaned_folder = os.path.join(base_folder, \"cleaned_data\")\n",
    "\n",
    "os.makedirs(raw_folder, exist_ok=True)\n",
    "os.makedirs(cleaned_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# === STEP 1: SCRAPE REAL DATA ===\n",
    "def fetch_data():\n",
    "    print(\"\\nüîÑ Fetching live crypto data from CoinMarketCap...\")\n",
    "\n",
    "    url = \"https://coinmarketcap.com/\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}  # Prevent blocking\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"‚ùå Failed to fetch webpage.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Extract tables from HTML\n",
    "    tables = pd.read_html(response.text)\n",
    "    if not tables:\n",
    "        print(\"‚ö†Ô∏è No tables found on the page.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = tables[0]\n",
    "    print(f\"üì¶ Rows fetched: {len(df)}\")\n",
    "\n",
    "    # Save RAW data\n",
    "    raw_path = os.path.join(raw_folder, f\"raw_data_{date.today()}.csv\")\n",
    "    df.to_csv(raw_path, index=False)\n",
    "    print(f\"‚úÖ Raw data saved to: {raw_path}\")\n",
    "\n",
    "    print(\"ü™£ Data Preview:\")\n",
    "    print(df.head(), \"\\n\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# === STEP 2: CLEAN DATA ===\n",
    "def clean_data(df):\n",
    "    if df.empty:\n",
    "        print(\"‚ö†Ô∏è No data to clean. Skipping cleaning step.\")\n",
    "        return\n",
    "\n",
    "    # Basic cleaning\n",
    "    df.columns = [col.strip().replace('\\n', '_') for col in df.columns]\n",
    "    df = df.dropna(subset=[df.columns[0]])\n",
    "    df = df.drop_duplicates()\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Save CLEANED data\n",
    "    cleaned_path = os.path.join(cleaned_folder, f\"cleaned_data_{date.today()}.csv\")\n",
    "    df.to_csv(cleaned_path, index=False)\n",
    "    print(f\"üßπ Cleaned data saved to: {cleaned_path}\")\n",
    "\n",
    "\n",
    "# === RUN PIPELINE ===\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nüöÄ Running Daily Crypto Web Scraping Pipeline...\\n\")\n",
    "    raw_df = fetch_data()\n",
    "    clean_data(raw_df)\n",
    "    print(\"\\nüéØ Pipeline complete!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184158a4-0862-49e5-8747-f1c27903838e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
